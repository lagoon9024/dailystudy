# Tensorflow CNN 사용해보기 - 전처리과정(convolution & pooling layer)

### Test (참고 :: [모두를 위한 딥러닝](http://bit.ly/2HHrybT))
- 3 by 3 Toy이미지 생성 및 필터 convolution 실습[source](./train.py)
- Toy image code
```python
import tensorflow as tf
from tensorflow import keras #tf의 keras를 활용해야한다. 그냥 keras와 모듈이 다른듯
import numpy as np
import matplotlib.pyplot as plt

image = tf.constant([[[[1],[2],[3]],
[[4],[5],[6]],
[[7],[8],[9]]]], dtype=np.float32)

print(image.shape)
#shape print (1,3,3,1) => 4 dimension data (batch, height, width, channel)

plt.imshow(image.numpy().reshape(3,3),cmap='Greys') 
#numpy image show with reshape 1,3,3,1 to 3,3 and color map grey
plt.show()
```
 - conv2d input/output shape

>Input shape
4D tensor with shape: (batch, channels, rows, cols) if data_format is  "channels_first"  or  4D tensor with shape: (batch, rows, cols, channels) if data_format is  "channels_last".

>Output shape
4D tensor with shape: (batch, filters, new_rows, new_cols) if data_format is  "channels_first"  or  4D tensor with shape: (batch, new_rows, new_cols, filters) if data_format is  "channels_last". rows and cols values might have changed due to padding.

- 만든 이미지는 channels_last format

### 2 by 2 filter convolution
- not padded(size decrease)
```python
# 2 by 2 filter 적용
weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]]) 
# make filter(=mask), "." mean float data
print("weight.shape", weight.shape)
#(2,2,1,1) matrix
weight_init = tf.constant_initializer(weight) 
#initialize with weight matrix

conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='valid', kernel_initializer=weight_init)(image)

#filter count, filter_size, not padded

#option 'same' for zero-padding
print("conv2d.shape", conv2d.shape)
print(conv2d.numpy().reshape(2,2))

plt.imshow(conv2d.numpy().reshape(2,2),cmap='gray')
plt.show()
```
- zero-padded
```python
# 2by 2 filter width padding
weight = np.array([[[[1.]],[[1.]]],[[[1.]],[[1.]]]]) 
# make filter(=mask), "." mean float data
print("weight.shape", weight.shape)
#(2,2,1,1) matrix

weight_init = tf.constant_initializer(weight) 
#initialize with weight matrix
conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)
#filter count, filter_size, zero-padding

print("conv2d.shape", conv2d.shape)
print(conv2d.numpy().reshape(3,3))
plt.imshow(conv2d.numpy().reshape(3,3),cmap='gray')
plt.show()
```
- 3 channel filter 적용
```python
# 3 channel filter 적용
weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],[[[1.,10.,-1.]],[[1.,10.,-1.]]]]) 
# make filter(=mask), "." mean float data

print("weight.shape", weight.shape)
#(2,2,1,3) matrix, lastone mean channel count
weight_init = tf.constant_initializer(weight) 
#initialize with weight matrix

conv2d = keras.layers.Conv2D(filters=3, kernel_size=2, padding='same', kernel_initializer=weight_init)(image)
#filter count, filter_size, zero-padding

print("conv2d.shape", conv2d.shape)
feature_maps=np.swapaxes(conv2d,0,3) # 3channel 적용 결과를 출력하기 위해 27개 결과를 9개 단위로 나눔
for i, feature_map in  enumerate(feature_maps):
print(feature_map.reshape(3,3))
plt.subplot(1,3,i+1)
plt.imshow(feature_map.reshape(3,3),cmap='gray')
plt.show()
```

### Pooling(Maxpool) 적용 [source](./pooling.py)
- 출력 데이터(Activation Map)의 크기를 줄이거나특정 데이터 강조를 위해 적용
- Max Pooling으로 테스트
- test matrix
```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

# make sample matrix
image = tf.constant([[[[4],[3]],[[2],[1]]]], dtype=np.float32)
```
- pooling with option valid(크기 감소)
```python
# 2 by 2 matrix에 maxpool 적용
pool = keras.layers.MaxPool2D(pool_size=(2,2),strides=1,padding='valid')(image)

print(pool.shape)
# (1,1,1,1)로 pooling을 통해 matirx 크기 감소 확인
print(pool.numpy())
# 결과 [[[[4.]]]] 출력으로 maxpool 적용 확인
```
- pooling with option same(크기 감소 없음)
```python
# 2 by 2 결과 얻기 -> matrix에 zero-padding을 통해 진행
pool = keras.layers.MaxPool2D(pool_size=(2,2),strides=1,padding='same')(image)
# zero padding을 통해 matrix 감소를 막는다

print(pool.shape)
# (1,2,2,1)로 matrix 크기 동일함을 확인 가능
print(pool.numpy())
# 2 by 2의 형태의 matrix로 출력 확인
```

### convolution layer와 pooling layer 연계하기[source](./CNN_ex1.py)
- CNN의 구조를 보면 convolution layer와 pooling layer를 교차로 적용, 특징을 추출한다
- TF에 제공되는 MNIST 데이터를 활용해 적용해보았다
- MNIST DATA LOAD
```python
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

mnist= keras.datasets.mnist
class_names = ['0','1','2','3','4','5','6','7','8','9']
# 전처리만 수행하므로 classname이 사용되진 않았다

#data load
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.astype(np.float32)/255  #0~1사이 값으로 scaling
test_images = test_images.astype(np.float32)/255

img = train_images[0]
plt.imshow(img,cmap='gray')
plt.show()
```
- convolution layer 적용
```python
# convolution layer
img=img.reshape(-1,28,28,1)
# data를 4차원으로 변환, 원본 28*28pixel image
# reshape에 -1을 주게 되면 뒤의 값을 기준으로 해당 값을 자동 설정해준다
# 지금의 경우 28*28, 1 channel image 한개를 사용하므로 -1은 자동으로 1로 변환이 된다

img = tf.convert_to_tensor(img)
# tensor로 변환

weight_init=keras.initializers.RandomNormal(stddev=0.01)
# filter로 활용할 난수 tensor
# 정규 분포를 따르고, 난수의 평균 mean(default=0), 표준편차 stddev(default=0.05) 설정 가능

conv2d = keras.layers.Conv2D(filters = 5, kernel_size=3, strides=2, padding='same',kernel_initializer=weight_init)(img)
# stride를 2(=(2,2))로 설정했기 때문에, 두 칸씩 이동, convolution을 할 것이다
# 결과의 크기 역시 절반으로 감소할 것이다

print(conv2d.shape)
# (1,14,14,5)로 예상되는 결과 출력

feature_maps=np.swapaxes(conv2d,0,3)
for i,feature_map in  enumerate(feature_maps):
plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(14,14),cmap='gray')
# 감소한 크기 기준으로 출력
plt.show()
```
- pooling layer(max pool)
```python
# pooling layer
pool = keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding='same')(conv2d)
# 마찬가지로 stride를 2로 설정해 주었기 때문에 크기가 반으로 감소될 것이다

print(pool.shape)
# (1,7,7,5)로 예상되는 결과 출력
# 채널의 감소는 발생하지 않는 것을 확인 가능

feature_maps = np.swapaxes(pool,0,3)
for i,feature_map in  enumerate(feature_maps):
plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(7,7),cmap='gray')
# 감소한 크기 기준으로 출력
plt.show()

# 이후 Fully Connected(Dense) Layer로 연결하고 softmax를 통과하여 결과 도출
```
---
### 후기
- 결과를 통해 convolution 과 pooling layer의 적용 결과 확인을 할 수 있었음
- fully connected layer랑 softmax에 대한 공부를 더해야겠다
