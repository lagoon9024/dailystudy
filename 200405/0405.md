# AI 용어공부
<sub>Reference
[머신러닝 & 딥러닝 용어 정리](https://snowdeer.github.io/machine-learning/2018/01/04/machine-learning-terminologies/)  
[ReLU를 사용하는 이유](https://joonable.tistory.com/2)</sub>
### model
- 머신러닝을 통해 얻을 수 있는 최종 결과물
- 가설(Hypothesis) 라고도 부른다

### Overfitting(과적합)
- 학습 데이터에 최적화가 필요 이상으로 되어 실제 데이터와 차이가 많이 발생하는 모델을 만들게 되는 현상
- 학습 데이터에도 Noise가 섞여 있을 수 있기 때문에 Overfitting을 방지하는 기법을 적용해야 더 좋은 결과물 도출
- 반대로 Underfitting도 존재  
![Image](https://snowdeer.github.io/assets/machine-learning/014.jpg)

### Regularization, Validation
- Regularization
	- 학습 데이터를 일부 희생하더라도 모델을 최대한 간단히 만들어 Overfitting을 방지하는 기법
	- Regularization을 눈으로 보고 확인하 기 어렵기 때문에 Overfitting 여부 판단 어려움
	- 판단을 위해 Validation(검증) 기법 적용
- Validation
	- 검증용 데이터는 학습 데이터에 포함시키지 않고, 모델의 성능 검증에만 활용
	- 일반직으로 학습:검증 8:2비율로 사용
	- 검증 데이터를 고정하지 않고 무작위로 바꿔가며 사용하는 Cross Validation(교차 검증)기법도 있음

### Classification, Regression
- 둘 다 입력데이터로 {입력, 정답}의 형태를 가짐
- 분류의 경우 정답은 '범주'의 형태, 회귀의 경우 '값'의 형태를 가지는 차이가 있다
- Supervised Learning에 해당
- 비지도 학습의 Clustering(군집화)는 비슷한 데이터끼리 묶어주는 기능으로 다른 기능이다

### Neural Network
- 사람의 두뇌 형태를 본따 만든 모델로, 수많은 노드들과 각 노드들간의 weight로 구성  
![Image](https://snowdeer.github.io/assets/machine-learning/018.png)
- 학습 데이터를 이용해 학습하면서 결과값에 따라 각 노드 간의 가중치를 조정하는 학습 방법

### 델타 규칙
- Adaline, Widrow-Hoff 규칙이라고도 하며, 주어진 정보에 따라 단층 신경망의 가중치를 바꾸어주는 규칙
>**델타 규칙**(delta rule)은 경사 하강법(Gradient Descent) 학습 방법으로, 싱글 레이어 퍼셉트론에서 인공  뉴런들의 연결강도를 갱신하는데 쓰인다. 뉴런 ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/30f268d4be31700461b9f20cabb0724899ad5d27)와 활성함수  ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f7205fa02cb295a2fc35a03490e8e9276c57fd87)  에 대하여,  ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/30f268d4be31700461b9f20cabb0724899ad5d27)의  ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8288705aba0c3da0eae22f3895f572ecc2ccdf8)번째 연결강도 ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b2a9cfab1fc5918b9f6454f2e2fafbc429f9b4d8)에 대한 델타 규칙은 다음과 같다.
![{\displaystyle \Delta w_{ji}=\alpha (t_{j}-y_{j})g'(h_{j})x_{i}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cb2abbe33735dc29ca9dde430f6f8122e8518cd8),
![{\displaystyle \alpha \,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/652e1fd9c3a2ca00e1a517783cdbb0e18e4181f8)는  _학습 속도_  라고 불리는 작은값의 상수이고, ![{\displaystyle g(x)\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f7205fa02cb295a2fc35a03490e8e9276c57fd87)는 뉴런의 활성함수, ![{\displaystyle t_{j}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/64cc070672fe73fb215cf81bd834e2aafdd811aa)는 원하는 목표 결과값,  ![{\displaystyle y_{j}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c200b3ca057a992d1fda5c85195ded18a3385171)는 실제 결과값, 그리고 ![{\displaystyle x_{i}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7beb41cde977577a7aa598a9defd58dc8d529bb8)는  ![{\displaystyle i\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8288705aba0c3da0eae22f3895f572ecc2ccdf8)번째 입력값이다. 이것은 다음 식을 만족한다.
![{\displaystyle h_{j}=\sum x_{i}w_{ji}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f10778a0d00e6a3e806cec13c33c2d1098d0a3b1)  and ![{\displaystyle y_{j}=g(h_{j})\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d311b57535a523287a2c4274973f3245011585a0).
델타 규칙은 다음과 같은 선형 활성함수를 가진 간단한 형태의 퍼셉트론에서 주로 언급된다.
![{\displaystyle \Delta w_{ji}=\alpha (t_{j}-y_{j})x_{i}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1970928067118ab09d3037a644dda53246148164)
<sub>[위키피디아-델타규칙](https://ko.wikipedia.org/wiki/%EB%8D%B8%ED%83%80_%EA%B7%9C%EC%B9%99)</sub>

> 어떤 output node에서 오차(![{\displaystyle y_{j}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c200b3ca057a992d1fda5c85195ded18a3385171))가 발생했다면, output node와 input node 간 연결 가중치(![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b2a9cfab1fc5918b9f6454f2e2fafbc429f9b4d8))는 input node의 출력과 output node의 오차(![{\displaystyle \Delta w_{ji}=\alpha (t_{j}-y_{j})x_{i}\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1970928067118ab09d3037a644dda53246148164))에 비례해서 조절한다

> 여기서 alpha는 학습률을 의미. 0보다 크고 1보다 작거나 같은 값을 가진다
> 학습률이 너무 높으면 정답 근처에서 수렴을 못하는 경우가 발생할 수 있고, 너무 낮으면 학습속도가 아주 느릴 수 있음

### 재학습 및 epoch
- 델타 규칙은 정답을 한 번에 바로 찾는 것이 아니라 반복적인 학습 과정을 통해 정답을 도출
- 따라서 한 번 학습한 데이터도 전체 학습 데이터를 반복해서 학습하기도 한다
#### epoch
- 학습 데이터를 한 번씩 모두 학습시킨 횟수

### Backpropagation(오차 역전파)
- 델타 학습법으론 신경망의 모든 노드를 학습시킬 수 없음
- Hidden layer는 레이블이 없기 때문에 델타 규칙으로 학습이 불가
- Backpropagation이란 출력층부터 시작해 거꾸로 추적하며 가중치를 조절하는 방법  
![Image](https://snowdeer.github.io/assets/machine-learning/019.png)

### One-Hot Encoding(1 of N encoding)
- 결과가 0과 1이 아닌 3가지 이상의 범주를 가질 때 출력노드를 범주 갯수만큼, 각 자릿수마다 범주를 0과 1로 표현하는 방식  ![Image](https://snowdeer.github.io/assets/machine-learning/020.png)  
![Image](https://snowdeer.github.io/assets/machine-learning/021.png)

### 경사각 소실(Vanishing Gradient)
- 신경망의 계층이 깊어질 수록 성능이 떨어지는 이유들 중 하나
	- 경사각 소실
	- 과적합
	- 많은 계산량
- Activation function으로 많이 사용하는 Sigmoid 함수의 최대 기울기는 0.3을 넘지 않는다
- 곱할수록 0에 가까워지고 0에 수렴하게 되어 경사각이 소실되는 문제가 있음
- 대안으로 ReLU함수를 사용해 해결이 가능하다

### ReLU(Rectified Linear Unit)
![](https://t1.daumcdn.net/cfile/tistory/9954A93C5B06AAEB2D)
- ReLU의 수식(max(0,x)랑 같다..)
#### ReLu의 장점(vs. Sigmoid)
1. Sparsity(뉴런의 값 중 0이 많다)
-	Sigmoid를 활용하면 0(ex 0.00001, 0.03, etc..)이 아닌 어떠한 값을 만들어 내는 경향이 있어 dense한 모습을 보인다
-	뉴런의 활성화 값이 0이기 때문에 다음 레이어로 연결되는 weight를 곱하더라도 결과값은 0이 된다. 즉 dense한 형태보다 연산량이 월등히 줄어든다
	-	하지만 0으로 할당되면 다시 활성화 되지 않으므로 해당 뉴런을 dead neuron/dying ReLU라 표현하기도 함
![](https://t1.daumcdn.net/cfile/tistory/995DDF3C5B06AA402B)
<sub>파란색 박스는 a값이 0보다 큰 경우, 흰 박스는 0보다 작은 경우</sub>
2. Vanishing Gradient가 없다
![](https://t1.daumcdn.net/cfile/tistory/999AF5395B06AED927)
- 위의 그래프를 보면 알 수 있듯, tanh형태의 그래프를 보이는 Sigmoid는 x의 절대값이 커질수록 gradient가 0으로 수렴하여 Vanishing Gradient가 발생한다
- 하지만 ReLU의 경우 Gradient는 하나의 상수로 수렴하게 되어 일정한 Gradient를 갖게 된다
	- 빠르게 학습하는 데 도움이 된다 
---
#### 후기
- 용어에 대한 이해가 부족해서 따로 정리해보았다
- 여기 없는 부분은 또 찾아가면서 해야지 뭐..
