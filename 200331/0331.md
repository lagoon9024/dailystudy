# CNN(Convolution Neural Network)

### 개요
- Fully Connected Neural Network만으로 구성된 인공신경망의 입력은 1차원(배열) 형태로 한정
- RGB 이미지의 경우 3차원 데이터이고 배치 모드에 사용되는 여러장의 사진은 4차원 데이터
- FC(Fully Connected) 신경망으로 학습할 경우 3차원 데이터를 1차원으로 평면화 시켜야 함(Dimension reduction)
- 평면화를 통해 공간 정보의 손실이 발생하는데 이 손실을 방지한 채 학습이 가능한 모델이 CNN이다

### 주요 용어
-   Convolution(합성곱)
-   채널(Channel)
-   필터(Filter)
-   커널(Kernel)
-   스트라이드(Strid)
-   패딩(Padding)
-   피처 맵(Feature Map)
-   액티베이션 맵(Activation Map)
-   풀링(Pooling) 레이어

#### 합성곱(Convolution)
- 원 이미지에 필터(mask)를 shift하며 연산하여 Feature Map을 만드는 것을 의미함
![합성곱 처리 절치, 출처: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)
- 노란색을 필터(mask)로 보면 된다

#### 채널
- RGB 사진의 경우 3개의 채널(RED, GREEN, BLUE), GRAY SCALE 사진의 경우 한 개의 채널을 갖게 된다
- 즉, Convolution Layer에 유입되는 입력데이터에는 한 개 이상의 필터가 적용되는데, 1개 필터는 Feature Map의 채널이 된다
- n개의 필터가 적용된다면 출력 데이터는 n개의 채널을 갖게 된다

#### Fliter(=Kernel) & Stride
- 위의 이미지에서 masking 한 것이 필터
- CNN에서는 Filter와 Kernel은 같은 의미
- 일반적으로 3 by 3 또는 4 by 4 정사각 행렬로 정의
- CNN에서 학습의 대상은 필터 파라미터
- Stride란 필터를 순회하는 지정된 간격
- 위의 이미지는 Stride가 1이 된다
- 영상처리에서 필터(mask)와 동일한 개념

#### 이미지의 푸리에 변환
- 이미지의 변화가 심한경우 고주파, 변화가 적은 경우 저주파 성분을 많이 갖게 된다
- 푸리에 변환을 통해 공간 도메인 -> 주파수 도메인으로 변형을 시켜줄 수 있다
- DFT의 주기성을 활용, spectrum 결과를 shift 해주면 중앙은 저주파, 외부는 고주파의 형태로 변환이 가능
- 이를 활용하여 주파수 필터링이 가능하다 -> 마스크 설계에 활용 가능
![](https://t1.daumcdn.net/cfile/tistory/993C0C3359C8493E0D)
>- Shift 된 Spectrum의 중앙은 Low Freq. 외곽은 High Freq 정보를 갖는다
>- Frequency 정보는 이미지의 변화값(명암의 변화)가 클 수록 High Freq.의 성분을 갖게 된다


#### padding
- 필터를 거친 이미지를 원 이미지와 같은 크기로 유지하기 위함
- 마스크가 이미지의 영역을 벗어나는 것을 방지하기 위함
- 두 가지로 사용하는 것으로 기억하고... zero-padding으로 영상처리하여 외곽을 인식하는 학습 효과도 존재
#### Pooling 레이어
- 컨볼루션 레이어의 출력 데이터를 입력으로 받아 **출력데이터(Activation Map)의 크기를 줄이거나 특정 데이터를 강조**하는 용도로 사용
- Max/Average/Min Pooling 방식이 존재
- 예를 들어 Max Pooling의 경우 정사각 행렬 특정 영역 안에 값의 최대값을 모으는 방식으로 동작
- CNN의 경우 주로 Max Pooling을 사용
![Pooling 예제: Max Pooling, Average Pooling](https://taewanmerepo.github.io/2018/02/cnn/maxpulling.png)
-  Pooling Layer 의 특징 (Convolution Layer 대비)
	- 학습대상 파라미터가 없다
	- Pooling Layer 통과 후 행렬의 크기가 감소한다
	- Pooling Layer를 통해서 채널 수 변경이 없다
---
### 레이어 별 출력 데이터 산정
#### Convolution 레이어 출력 데이터 크기 산정
입력 데이터에 대한 필터와 Stride의 크기에 따라 Feature Map 크기 결정

-   입력 데이터 높이: H
-   입력 데이터 폭: W
-   필터 높이: FH
-   필터 폭: FW
-   Stride 크기: S
-   패딩 사이즈: P
> 출력 데이터 크기 계산 
$$OutputHeight= \frac {H+2P−FH} {S+1}$$ $$OutputWidth= \frac{W+2P−FW}{S+1}$$
- 결과는 자연수가 되어야 한다...

#### Pooling 레이어 출력 데이터 크기 산정
- 모든 요소가 한번씩 Pooling 되도록 만들기 위해 Stride와 Pooling 사이즈를 같게 만든다
- 풀링은 일반적으로 정사각형
- 즉, Pooling 레이어의 출력 데이터 크기는 행/열의 크기를 Pooling 사이즈로 나눈 몫
> 출력 데이터 크기 계산 
$$OutputRowSize= \frac {InputRowSize} {PoolingSize}$$ $$OutputColumnSize= \frac{InputColumnSize}{PoolingSize}$$

#### CNN 구성
CNN은 Convolution Layer와 Max Pooling Layer를 반복적으로 stack을 쌓는 **특징 추출(Feature Extraction) 부분**과 Fully Connected Layer를 구성하고 마지막 출력층에 Softmax를 적용한 **분류 부분**으로 나뉜다
![전형적인 CNN, 출처: https://www.researchgate.net/figure/Architecture-of-our-unsupervised-CNN-Network-contains-three-stages-each-of-which_283433254](https://taewanmerepo.github.io/2018/01/cnn/cnnexam.png)

CNN을 활용하면 Fully Connected Neural Network 대비 학습 파라미터수가 매우 작고(20% 규모), 학습이 쉬워 네트워크 처리속도가 빠른 강점이 있다

---
~~내일 더 써야징... 푸리에 기억이 가물가물해서 더 공부해야겠다~~
- 이제 직접 적용을 해봐야하겠다...
### Reference 
- CNN : http://taewan.kim/post/cnn/
- 푸리에변환 : https://darkpgmr.tistory.com/171
